% !TeX root = bachelorarbeit.tex

\subsection{Modellproblem}

In diesem Abschnitt wollen wir anhand des linearen Transportproblems auch tatsächliche praktische Resultate der Multilevel Monte Carlo Methode beleuchten.
Wir setzen dazu
\begin{itemize}
	\item $ \mathcal{D} = (0,1)^2 \subset \R^2 $ (also insbesondere wie bereits zuvor in der Theorie $ n=2 $)
	\item $ \mathbb{T} = [0,T] = [0,1] $ (vgl. Bemerkung \ref{wahlfunk})
	\item $ \rho_{\text{in}} \equiv 0 $
	\item $ \rho_0(x) = 
	\begin{cases*}
		\begin{array}{llll}
			&c & , &\text{für }x \in B \coloneqq [0.2,0.8] \times [0.7 ,0.8]  \\
			&c\exp \left(\frac{ \left| \frac{\text{dist}(x,B)}{0.15} \right| ^2}{\left|\frac{\text{dist}(x,B)}{0.15}\right|^2-1}\right) &, &\text{falls } x \not \in B \text{ und dist}(x,B) < 0.15 \\
			&0 &, & \text{sonst}
		\end{array}
	\end{cases*}$ \\
	Dabei sei $ c $ so gewählt, dass 
	\[
		\int_{\mathcal{D}} \rho_0(x) \dx = 1 \ ,
	\]
	wir skalieren also die zu Beginn im Rechengebiet enthaltene Masse auf $ 1 $.
\end{itemize} 
Die Anfangskonzentration $ \rho_0 $ entspricht also gerade einer rechteckigen Ansammlung mit Länge $ 0.6$ und Breite $ 0.1$ und Mittelpunkt $ (0.5,0.75) $, welcher in beide Richtungen auf einem $ 0.15$ breiten Streifen mit einer Exponentialfunktion in die Ebene geglättet wird. 
Wir stellen so für die Anfangsbedingungen unseres Modellproblems einen sehr hohen Grad an Regularität sicher. 
Visuell kann diese Anfangskonzentration folgendermaßen dargestellt werden:
\begin{figure}[H]
	\centering
	\captionabove{Anfangsbedingung $ \rho_0 $}
	\includegraphics[width=0.65\textwidth]{plots/anfangsbedingung.png} 
\end{figure}
Der Maximalwert ist dabei so gewählt, dass die Gesamtmasse der Anfangsbedingung gerade den Wert $ 1 $ ergibt.\\
Uns interessiert nun folgende Fragestellung: \\
\textbf{Wie groß ist der erwartete Anteil der Masse, welcher nach Ablauf des betrachteten Zeitintervalls $ \mathbb{T} $ im Rechengebiet $ \mathcal{D} $ verbleibt?}\\

Wie bereits an früherer Stelle erklärt, berechnen wir hierzu ein stochastisches Flussvektorfeld $ q : \Omega \times \overline{\mathcal{ D}} \to \R^2 $ als Lösung des zugehörigen Potentialströmungsproblems, wobei wir dabei den Permeabilitätstensor $ \kappa : \Omega \times \mathcal{D} \to \R_{\geq0} $ als lognormal verteiltes Zufallsfeld modellieren. Wir identifizieren dabei die Verteilung von $ \kappa $ mit der zugehörigen Kovarianzfunktion:
\[
 C(x,y) = \sigma^2 \exp(- \frac{\lVert x-y \rVert_2^s}{\lambda^s} ) .
\]
Dabei ist $ 0 < \sigma^2 < \infty $ die Varianz des zugrundeliegenden Gauß'schen Zufallsfeldes, durch $ \lambda = (\lambda_1,\lambda_2) \in \R^2 $ werden die Korrelationslängen in die verschiedenen Koordinatenrichtungen gegeben und $ s \in (1,2) $ ist ein Glättungsparameter. Wir wählen an dieser Stelle :
\begin{align*}
s &=  1.9\\
\lambda_1,\lambda_2 &= 0.15\\
\sigma &= 1.0
\end{align*}
Wir können auch das lognormal verteilte Zufallsfeld und das daraus resultierende stochastische Flussvektorfeld $ q $ exemplarisch für ein $ \omega \in \Omega $ grafisch darstellen. Bei der Visualisierung des Flussvektorfeldes nutzen wir dabei einen sogenannten 'Quiverplot'. Im Wesentlichen wird dabei das Flussvektorfeld auf einem Gitter ausgewertet und die resultierenden Vektoren mithilfe eines Skalierungsparameters skaliert, damit die so eingezeichneten Vektoren eine dem Gitter angepasste Länge besitzen.

\begin{figure}[H]
	\centering
	\captionabove{Visualisierung der stochastischen Modellierung}
	\subfigure[lognormal verteiltes Zufallsfeld mit obigen Parametern]{\includegraphics[width=0.49\textwidth]{plots/perm.png}}
	\subfigure[Zufallsfeld und zugehöriges  Flussvektorfeld]{\includegraphics[width=0.49\textwidth]{plots/permquiv.png}}
	
\end{figure}

Weiter setzen wir
\begin{itemize}
	\item $\Gamma_{\text{D}} = \{ x = (x_1,x_2) \in \overline{\mathcal{D}} : x_2 = 0 \} $
	\item $ \Gamma_{\text{N}} = \partial \mathcal{D} \setminus \Gamma_{\text{D}} $
	\item $ g_N = \begin{cases}
						\begin{array}{llll}
						    &0 &, &\text{falls } x \in \{ x \in \Gamma_{\text{N}} : x_1 \in \{ 0,1 \}  \} \\
						    &1 &,& \text{sonst}
						\end{array}
				  \end{cases} $
	\item $ u_D \equiv 0 \text{ auf } \Gamma_{\text{D}} $
	
\end{itemize}

Als Zerlegung von $ \mathcal{D} $ wählen wir gleichartige Quadrate. Um auf dem geringsten Level ein Mindestmaß an Auflösung zu gewährleisten, wählen wir auf Level $ l_0 $ eine Zerlegung in $ 256 = 16^2 $ Quadrate. Dies entspricht einer Ortsdiskretisierungsschrittweite von $ h_0 = \frac{1}{16} = 0.0625 $. Wie bereits im Theorieteil angemerkt, wählen wir von $ h_0 $ ausgehend die uniforme Familie von Zerlegungen $ \{\mathcal{T}_h \}_{h \in \mathcal{H}} $ mit $ \mathcal{H} = \{ h_0 , h_1 \coloneqq \frac{h_0}{2},h_2 \coloneqq \frac{h_1}{2} = \frac{h_0}{4}, \dots \} $. Auf Level $ l_1 $ betrachten wir also $ 1024 = 32^2 $ und auf Level $ l_k $ dementsprechend $ 2^{2(k+4)} $ Quadrate. 
In M++ entspricht Level $ l_0 $ bei der gewählten Diskretisierung 'UnitSquare' gerade Level $ 4 $. Die Zerlegungen auf $ l_0 = 4, l_1 = 5 $ und $ l_2 = 6 $ lassen sich folgendermaßen darstellen:
\begin{figure}[H]
	\centering
	\captionabove{Zerlegung des Gebietes $ \mathcal{D} $ in Finite Elemente}
	\subfigure[$l_0 = 4$ (256 Zellen)]{\includegraphics[width=0.31\textwidth]{plots/mesh4.png}}
	\subfigure[$l_1 = 5$ (1024 Zellen)]{\includegraphics[width=0.31\textwidth]{plots/mesh5.png}}
	\subfigure[$l_2 = 6$ (4096 Zellen)]{\includegraphics[width=0.31\textwidth]{plots/mesh6.png}}
\end{figure}
Die Schrittweite für die Diskretisierung in der Zeit setzen wir auf $ \Delta t = \frac{h}{8} $. Diese Wahl ist besonders hinsichtlich der Stabilität des Verfahrens wichtig. Bei zu kleinen Zeitschrittweiten treten Oszillationen in der Lösung auf. Obige Wahl hat sich für unser Problem als hinreichend erwiesen.
Entsprechend unserer Fragestellung können wir nun das betrachtete Zielfunktional formulieren:
\[
Q(\omega) = J(\rho(\omega)) \coloneqq \int_{\mathcal{D}} \rho(\omega,x,T) \dx = \int_{\mathcal{D}} \rho(\omega,x,1) \dx
\]
Wir suchen gemäß unserer Fragestellung also gerade nach $ \mathbb{E}[Q] $.
\begin{Bemerkung2}\label{wahlfunk}
	Die Wahl $ T=1 $ ist an dieser Stelle gerade so getroffen, dass das der Fragestellung entsprechende Zielfunktional in gewisser Weise interessant ist. 
	Genauer ist $ T $ so gewählt, dass die im Algorithmus auftretende Varianz $ \mathbb{V}[Y_l] $ 'groß' ausfällt. Ist $ T $ nämlich zu groß gewählt, befindet sich für fast alle $ \omega \in \Omega $ kaum noch Masse im Gebiet und die erwartete Endmasse ist $ \mathbb{E}[Q] = 0 $, während für sehr kleine $ T $ Masse zum Zeitpunkt $ T $ für fast alle $ \omega \in \Omega $ mit der Anfangsmasse übereinstimmt und somit $ \mathbb{E}[Q] = 1$. Für $ T = 1 $ erhalten wir für verschiedene $ \omega \in \Omega $ recht unterschiedliche Ergebnisse, da die Masse je nach Beschaffenheit des Flussvektorfeldes schneller oder langsamer durch das Gebiet transportiert wird. 
\end{Bemerkung2}
Einen guten kompakten Überblick über ein einzelnes Sample bietet folgende Darstellung:
\begin{figure}[H]
	\centering
	\captionabove{Verlauf der Konzentration eines Beispielsamples auf Level $ l_3=7 $}
	\includegraphics[width=\textwidth]{plots/solution3.png} 
\end{figure}
Die Abbildung links zeigt die Anfangsbedingung zum Zeitpunkt $ t=0 $, in der Mitte ist ein Zwischenschritt der Lösung (zum Zeitpunkt $ t=0.5 $ zu sehen) sowie das zum Sample zugehörige Flussvektorfeld zu sehen. Wir wollen an dieser Stelle noch einmal darauf hinweisen, dass wir das Flussvektorfeld als Lösung eines statischen Problems erhalten. Insbesondere ist also das Flussvektorfeld nicht zeitabhängig und könnte gleichermaßen auch bei Anfangs- und Endzustand eingezeichnet werden. 
Wir berechnen diesen Erwartungswert nun gemäß Abschnitt 6 mit der Multilevel Monte Carlo Methode für die Startwerte $ l_0 = 4, L_0 = 7, N_0 = \{n_4,\dots,n_7\} = \{16,8,4,2\} $und $ \epsilon \in \{0.01,0.005,0.003,0.001\} $.
\subsubsection{Verarbeiten und Darstellen von Vtk-Dateien}
In M++ werden zur Speicherung von Gitterdaten sogenannte Vtk-Dateien genutzt. Alle obigen sowie noch folgende Schaubilder wurden aus diesen Vtk-Dateien generiert. Dafür wurden im Rahmen der Thesis einzelne Module in Python implementiert, welche den Umgang mit diesen Vtk-Dateien erleichtern. 
\begin{figure}[H]
	\centering
	\captionabove{Überblick über implementierte Module}
	\includegraphics[width=\textwidth]{plots/klassenuml2.png} 
\end{figure}
Wie oben anhand der Klassenstrukturen dargestellt, können die Module in 6 Gruppen unterteilt werden. Gruppe 1 ermöglicht auf Grundlage des externen Moduls 'vtk' \cite{sitevtk} das Lesen von Vtk Dateien. Insbesondere ist es möglich, die Gitterdaten in sogenannten 'numpy-Arrays' zu exportieren. 
Gruppe 2 implementiert ein Interface zum Erstellen verschiedener Schaubilder aus den eingelesenen Vtk Dateien. Im später im Appendix beigefügten Notebook und den entsprechenden Skripten im Hintergrund sind einige exemplarische Beispiele vorhanden. Außerdem wurden alle Schaubilder dieser Thesis über dieses Interface erstellt.
In Gruppe 3 werden die eingelesenen Arrays wieder als 'UnstructuredMesh' aufgefasst. Die Lösungen des Transportproblems selbst bestehen aufgrund der Zeitabhängigkeit aus mehreren Gittern. Deshalb fassen wir diese als 'UnstructuredMultiScalarMesh' auf. Das Flussvektorfeld hingegen trägt als Daten Vektoren in jeder Zelle und wird deshalb als 'UnstructuredVectorMesh' betrachtet. Diese objektorientierte Unterteilung zieht sich bis auf Gruppe 2 durch alle Gruppen und ermöglicht den Umgang mit einzelnen Gittern und Skalaren, beispielsweise die Permeabilität des Bodens, mit einzelnen Gittern und Vektordaten, wie etwa das Flussvektorfeld, oder aber einer ganzen Gruppe von Gittern mit Skalaren, womit sich die zeitabhängige Lösung darstellen lässt. Wir können so die Lösungen der Samples als Gitterdaten auffassen und bearbeiten. Insbesondere wurden beispielsweise die Addition und Subtraktion von Gitterdaten implementiert, welche für Generierung von weiteren Gittern nach Vorbild der im Experiment durchgeführten Monte Carlo und Multilevel Monte Carlo Methoden unabdingbar sind. Unter anderem wurde dafür auch eine 'Upscale'-Methode entworfen, welche es ermöglicht, unterschiedlich feine Quadratgitter miteinander zu verrechnen.
Gruppe 4 und 5 kombinieren die von M++ während des Experiments abgespeicherten Vtk Dateien, wie oben beschrieben. Im Folgenden nennen wir die so (in Form von Gitterdaten) erzeugte Lösung auch 'MLMC-Lösung'.
Gruppe 6 dient dem Testen der anderen Gruppen in der Form sogenannter 'UnitTests'.
Der Code und weitere zusätzliche Informationen sind auch im zugehörigen Github-Repository \cite{githubvtk} zu finden. Das Notebook und die in das MLMC Framework eingearbeiteten Skripte finden sich auch unter \cite{branchMLMCTP}.

\subsection{Ergebnisse}
\subsubsection{Konvergenztest}
Bevor wir auf die Ergebnisse des eigentlichen Experiments eingehen, wollen wir einen kurzen Blick auf die Ergebnisse des Konvergenztests werfen. Dieser Test ist dafür da, die Annahmen, welche wir unter anderem für \eqref{MLMCTheorem} getroffen hatten, für unser konkretes Problem nachzuweisen.
Konkret erhalten wir bei der Auswertung von 100 Samples pro Level (und den jeweiligen Vergleichssamples) folgende Ergebnisse:

\newlength\q
\setlength\q{\dimexpr .125\textwidth -2.0\tabcolsep}
\noindent\begin{tabular}{|p{0.15\q}|p{0.55\q}|p{1.4\q}|p{1.05\q}|p{1.35\q}|p{1.25\q}|p{0.9\q}|p{1.35\q}|}
	\hline
	$ l $   &  $ M $  &  $ \mathbb{E}[Q_f-Q_c] $  &   $ \mathbb{E}[Q_f] $ &  $ \mathbb{V}[Q_f-Q_c] $   &   $ \mathbb{V}[Q_f] $ &  kurtosis    &    cost\\
	\hline
	4 &  100&    0.206865 &   0.206865&   0.0159427 &  0.0159427 &     2.4997&      294912 \\
	5 &  100&  0.00155785 &   0.229484&  3.2821e-05 &   0.024385 &    4.00513&  2.3593e+06 \\
	6 &  100&  0.00081706 &   0.185469& 1.61547e-06 &  0.0186312 &    3.99497& 1.88744e+07 \\
	7 &  100& 6.29135e-05 &   0.221811& 2.65752e-08 &  0.0239019 &    2.75915& 1.50995e+08 \\
	8 &  100& 1.86929e-05 &   0.221853& 2.63677e-09 &  0.0209867 &    3.37952& 1.20796e+09 \\
	\hline
	\multicolumn{2}{|c|}{$ \mathbb{E}[Q] $ }  &  \multicolumn{2}{c|}{MLMC Cost}   & \multicolumn{2}{c|}{$ l $}  &    \multicolumn{2}{c|}{$ M$} \\
	\hline
	\multicolumn{2}{|c|}{0.226436} & \multicolumn{2}{c|}{1.52352e+09  } &  \multicolumn{2}{c|}{   4 5 6 }     & \multicolumn{2}{c|}{4374 59 5}    \\
	\hline 
\end{tabular}\\

Stellen wir die Erwartungswerte und Varianzen obiger Tabelle als Verlauf über die verschiedenen Level dar, erhalten wir:

\begin{figure}[H]
	\centering
	\captionabove{Erwartungswerte und Varianzen im Konvergenztest }
	\includegraphics[width=\textwidth]{plots/mlmckonv.png} 
\end{figure}

Um nun die getroffenen Annahmen zu überprüfen, müssen wir die Konvergenzparameter aus \eqref{MLMCTheorem} bestimmen.
Wir schätzen an dieser Stelle $ \alpha $, also den Exponent der schwachen Konvergenz des Verfahrens, durch den Logarithmus der Steigung einer lineare Regressionsgerade der Erwartungswerte $ \mathbb{E}[Q_f - Q_c] $ gegenüber der Level. Anzumerken ist hierbei, dass auf dem Basislevel, hier Level 4, keine Differenz in Spalte 3 und 5 angegeben werden kann, da auf dem Basislevel nur einzelne Samples ohne gröberes Vergleichssample betrachtet werden. Stattdessen werden hier in Spalte 3 und 5 ebenfalls wie in Spalte 4 und 6 der einzelne Erwartungswert bzw. die einzelne Varianz angegeben. Bei der Schätzung von $ \alpha $ wird deshalb das Basislevel nicht einbezogen.
Den Exponenten des Rückgangs der Varianz $ \beta $ schätzen ähnlich wie $ \alpha $ als Logarithmus der Steigung einer Regressionsgeraden, diesmal über den den Rückgang der empirischen Varianzdifferenzen  $ \mathbb{V}[Q_f-Q_c] $ für die entsprechenden Level. Die Kosten in der letzten Spalte werden während des Experiments über die Anzahl der Freiheitsgrade des zugrunde liegenden linearen Gleichungssystems abgeschätzt. 
Auf Grundlage dieser geschätzten Kosten lässt sich dann genauso $ \gamma $ als Logarithmus der Steigung einer entsprechenden linearen Regression über die pro Level erwarteten Kosten $ \mathbb{E}[C_l] $ bestimmen. Da in unserer Schätzung die Kosten der Samples auf einem Level konstant ist, stimmt dieser Erwartungswert mit den Kosten jedes einzelnen Samples überein.  
Konkret erhalten wir mit obigen Daten also: 

\begin{align*}
\alpha &=2.28418 \\
\beta &=4.67364 \\
\gamma &=  3\\
\end{align*}
Insbesondere sind somit (zumindest gemäß den vorgenommenen Schätzungen) die getroffenen Annahmen für das betrachtete Problem erfüllt.
\subsubsection{Einige Beispielsamples}
Um einen ersten Eindruck über die berechneten Samples zu gewinnen, ist es hilfreich einige Beispielsamples zu betrachten. Im Experiment werden wir Samples auf den Levels $ 4,5,6 $ und $ 7 $ betrachten. Im Folgenden sind daher zu diesen Levels je ein Beispielsample dargestellt.
\begin{figure}[H]
	\centering
	\captionabove{Verlauf der Konzentration eines Samples auf Level $ l_0 = 4 $}
	\includegraphics[width=\textwidth]{plots/sample_4_1.png} 
\end{figure}
\begin{figure}[H]
	\centering
	\captionabove{Verlauf der Konzentration eines Samples auf Level $ l_1 = 5 $ und des zugehörigen Vergleichssamples auf Level $ l_0 = 4 $}
	\includegraphics[width=\textwidth]{plots/sample_5_1.png} 
	\includegraphics[width=\textwidth]{plots/sample_coarse_5_1.png} 
\end{figure}
An diesem direkten Vergleich sieht man sehr schön, dass sich die beiden Vergleichssamples zwar im Level unterscheiden, aber sich auf dasselbe Zufallsereignis $ \omega_i $ beziehen. Noch offensichtlicher wird das, je höher das aktuell betrachtete Level ist.
%\begin{figure}[H]
%	\centering
%	\captionabove{Verlauf der Konzentration eines Samples auf Level $ l_2 = 6 $ und des zugehörigen Vergleichssamples auf Level $ l_1 = 5 $}
%	\includegraphics[width=\textwidth]{plots/sample_6_0.png} 
%	\includegraphics[width=\textwidth]{plots/sample_coarse_6_0.png} 
%\end{figure}
So erscheinen die Vergleichssamples auf dem höchsten betrachteten Level nahezu identisch:
\begin{figure}[H]
	\centering
	\captionabove{Verlauf der Konzentration eines Samples auf Level $ l_3 = 7 $ und des zugehörigen Vergleichssamples auf Level $ l_2 = 6 $}
	\includegraphics[width=\textwidth]{plots/sample_7_0.png} 
	\includegraphics[width=\textwidth]{plots/sample_coarse_7_0.png} 
\end{figure}
\subsubsection{$ \epsilon=0.01 $}
Wir führen das Experiment für vier verschiedene Werte von $ \epsilon $ durch und beginnen mit dem größten Wert $ \epsilon=0.01 $. Wir erhalten: 


\noindent\begin{tabular}{|p{0.15\q}|p{0.55\q}|p{1.4\q}|p{1.05\q}|p{1.35\q}|p{1.25\q}|p{0.9\q}|p{1.35\q}|}
	\hline
	$ l $   &  $ M $  &  $ \mathbb{E}[Q_f-Q_c] $  &   $ \mathbb{E}[Q_f] $ &  $ \mathbb{V}[Q_f-Q_c] $   &   $ \mathbb{V}[Q_f] $ &  kurtosis    &    cost\\
	\hline
	4 &  378 &   0.225017  &  0.225017 &  0.0161076 &  0.0161076  &    2.9913&      294912 \\
	5 &    6 & 0.00142942  &  0.261486 &2.27982e-05 &  0.0158132  &   3.92345&  2.3593e+06 \\
	6 &    2 & 0.00132101  &  0.106957 &4.09672e-07 & 0.00590853  &         1& 1.88744e+07 \\
	7 &    2 & 5.6257e-05  &  0.125627 &      1e-10 &0.000783613  &  0.110661& 1.50995e+08 \\
	\hline
	\multicolumn{2}{|c|}{$ \mathbb{E}[Q] $ }  &  \multicolumn{2}{c|}{MLMC Cost}   & \multicolumn{2}{c|}{$ l $}  &    \multicolumn{2}{c|}{$ M$} \\
	\hline
	\multicolumn{2}{|c|}{0.227824} & \multicolumn{2}{c|}{4.65371e+08  } &  \multicolumn{2}{c|}{   4 5 6 7}     & \multicolumn{2}{c|}{  378 6 2 2}    \\
	\hline 
\end{tabular}\\
Wieder lohnt es sich $ \mathbb{E}[Q_f-Q_c] $ und $ \mathbb{V}[Q_f-Q_c] $ auf den verschiedenen Levels zu vergleichen:
\begin{figure}[H]
	\centering
	\captionabove{Erwartungswerte und Varianzen für $ \epsilon=0.01 $ }
	\includegraphics[width=\textwidth]{plots/eps001.png} 
\end{figure}
Wie bereits oben beim Konvergenztest können wir auch auf Grundlage dieser Daten die Konvergenzparameter $ \alpha, \beta $ und  $ \gamma $ schätzen:
\begin{align*}
\alpha  &=     2.33362   \\
\beta   &=    8.89928   \\
\gamma  &=    3  \\
\end{align*}

Zudem können wir auch die einzelnen Fehlerkomponenten abschätzen, diese Fehlerschätzung wird auch im Algorithmus selbst vorgenommen. So lässt sich der statistische Fehler darstellen durch \[
\text{statErr} \leq \sqrt{\sum_l   \frac{\mathbb{V}[Q_f-Q_c]}{M_l}} \ . \] 
Den numerischen Fehler können wir über einen Romberg Fehlerschätzer abschätzen und nutzen dabei die Abschätzung \[ \left| \mathbb{E}[Q_f-Q_c] \right| < (2^{\alpha}-1)\frac{\epsilon}{2} \ . \] Mehr zu obigen Fehlerschätzern und eine Erklärung für obige Abschätzung findet sich in \cite{giles_2015}.
Wir erhalten an dieser Stelle so: 
\begin{align*}
\text{numErr}  &=  0.000163463   \quad \text{(geschätzter numerischer Fehler)}\\
\text{statErr} &= 0.00682769  \quad  \text{(geschätzter statistischer Fehler)}\\
\text{error}   &= 0.00699115   \quad  \text{(geschätzter Gesamtfehler)}\\
\end{align*}



\subsubsection{$ \epsilon=0.005 $}

\noindent\begin{tabular}{|p{0.15\q}|p{0.55\q}|p{1.4\q}|p{1.05\q}|p{1.35\q}|p{1.25\q}|p{0.9\q}|p{1.35\q}|}
	\hline
	$ l $   &  $ M $  &  $ \mathbb{E}[Q_f-Q_c] $  &   $ \mathbb{E}[Q_f] $ &  $ \mathbb{V}[Q_f-Q_c] $   &   $ \mathbb{V}[Q_f] $ &  kurtosis    &    cost\\
	\hline
	4 & 1539 &   0.223618  &  0.223618&    0.016789&    0.016789 &    2.86354&      294912  \\
	5  &  22 & 0.00136769  &  0.257407& 1.64094e-05&   0.0231786 &    3.11973&  2.3593e+06 \\
	6   &  2 & 0.00132101  &  0.106957& 4.09672e-07&  0.00590853 &          1& 1.88744e+07 \\
	7    & 2 & 5.6257e-05  &  0.125627&       1e-10& 0.000783613 &   0.110661& 1.50995e+08 \\
	\hline
	\multicolumn{2}{|c|}{$ \mathbb{E}[Q] $ }  &  \multicolumn{2}{c|}{MLMC Cost}   & \multicolumn{2}{c|}{$ l $}  &    \multicolumn{2}{c|}{$ M$} \\
	\hline
	\multicolumn{2}{|c|}{0.226363} & \multicolumn{2}{c|}{8.45513e+08  } &  \multicolumn{2}{c|}{  4 5 6 7 }     & \multicolumn{2}{c|}{1539 22 2 2}    \\
	\hline 
\end{tabular}\\
\begin{figure}[H]
	\centering
	\captionabove{Erwartungswerte und Varianzen für $ \epsilon=0.005 $ }
	\includegraphics[width=\textwidth]{plots/eps005.png} 
\end{figure}
\begin{align*}
\alpha  &=     2.30178   \\
\beta   &=    8.66208   \\
\gamma  &=    3   \\
\text{numErr}  &=  0.00016804   \quad \text{(geschätzter numerischer Fehler)}\\
\text{statErr} &= 0.00344381  \quad  \text{(geschätzter statistischer Fehler)}\\
\text{error}   &= 0.00361185  \quad  \text{(geschätzter Gesamtfehler)}\\
\end{align*}


\subsubsection{$ \epsilon=0.003 $}
\noindent\begin{tabular}{|p{0.15\q}|p{0.55\q}|p{1.4\q}|p{1.05\q}|p{1.35\q}|p{1.25\q}|p{0.9\q}|p{1.35\q}|}
	\hline
	$ l $   &  $ M $  &  $ \mathbb{E}[Q_f-Q_c] $  &   $ \mathbb{E}[Q_f] $ &  $ \mathbb{V}[Q_f-Q_c] $   &   $ \mathbb{V}[Q_f] $ &  kurtosis    &    cost\\
	\hline
	4 & 4374&    0.224298 &   0.224298&   0.0169387 &  0.0169387  &   2.75002 &     294912 \\
	5  &  59 & 0.00141127  &  0.231847 & 2.14581e-05 &  0.0239913  &   2.59309 & 2.3593e+06\\
	6   &  5  &0.000726783  &  0.104317 & 9.88656e-07 & 0.00614564  &   1.66323 &1.88744e+07\\
	\hline
	\multicolumn{2}{|c|}{$ \mathbb{E}[Q] $ }  &  \multicolumn{2}{c|}{MLMC Cost}   & \multicolumn{2}{c|}{$ l $}  &    \multicolumn{2}{c|}{$ M$} \\
	\hline
	\multicolumn{2}{|c|}{0.226436} & \multicolumn{2}{c|}{1.52352e+09  } &  \multicolumn{2}{c|}{   4 5 6 }     & \multicolumn{2}{c|}{4374 59 5}    \\
	\hline 
\end{tabular}\\
\begin{figure}[H]
	\centering
	\captionabove{Erwartungswerte und Varianzen für $ \epsilon=0.003 $ }
	\includegraphics[width=\textwidth]{plots/eps003.png} 
\end{figure}
Auffällig ist hier, dass im Gegensatz zu den anderen Durchläufen kein viertes Level angehängt wird. Tatsächlich genügen an dieser Stelle sogar die ersten drei Level um die erwünschte Genauigkeit zu erzielen. Allerdings fällt dafür der Konvergenzparameter $ \alpha $ etwas schlechter aus. Grund dafür ist, dass hier eine lineare Regression auf Grundlage von nur zwei Datenpunkten durchgeführt wird. Hinzukommt, dass die Erwartungswerte $ \mathbb{E}[Q_f-Q_c] $ von Level 5 zu 6 in allen Durchläufen etwas flacher abfällt, als etwa von 6 zu 7 in den anderen Durchläufen. Zur Ursache dieser Beobachtung können wir aktuell nur Vermutungen anstellen, zu einem stichhaltigem Resultat sind noch weitere Analysen nötig.
\begin{align*}
\alpha  &=    0.957394   \\
\beta   &=    4.43991   \\
\gamma  &=    3   \\
\text{numErr}  &= 0.000771696   \quad \text{(geschätzter numerischer Fehler)}\\
\text{statErr} &= 0.00210571  \quad  \text{(geschätzter statistischer Fehler)}\\
\text{error}   &= 0.00287741  \quad  \text{(geschätzter Gesamtfehler)}\\
\end{align*}


\subsubsection{$ \epsilon=0.001 $}

\noindent\begin{tabular}{|p{0.15\q}|p{0.54\q}|p{1.4\q}|p{1.05\q}|p{1.35\q}|p{1.25\q}|p{0.9\q}|p{1.35\q}|}
\hline
$ l $   &  $ M $  &  $ \mathbb{E}[Q_f-Q_c] $  &   $ \mathbb{E}[Q_f] $ &  $ \mathbb{V}[Q_f-Q_c] $   &   $ \mathbb{V}[Q_f] $ &  kurtosis    &    cost\\
\hline
4 & 44254  & 0.226394   &  0.226394 &  0.0174305   &  0.0174305  &   2.65924   &   294912    \\
5 &  755   & 0.00168666 &  0.21234  &  4.12796e-05 &  0.0198136  &   3.68994   &   2.3593e+06\\
6 &   58   & 0.000869439&  0.20211  &  1.83935e-06 &   0.020755  &   3.80032   &   1.88744e+07 \\
7 &    5   & 7.68982e-05&    0.218324&  9.1227e-09&  0.00718929   &  2.45257 &1.50995e+08 \\
\hline 
 \multicolumn{2}{|c|}{$ \mathbb{E}[Q] $ }  &  \multicolumn{2}{c|}{MLMC Cost}   & \multicolumn{2}{c|}{$ l $}  &    \multicolumn{2}{c|}{$ M$} \\
\hline
 \multicolumn{2}{|c|}{0.229027} & \multicolumn{2}{c|}{1.6682e+10  } &  \multicolumn{2}{c|}{  4 5 6 7 }     & \multicolumn{2}{c|}{44254 755 58 5}    \\
\hline 
\end{tabular}\\

\begin{figure}[H]
	\centering
	\captionabove{Erwartungswerte und Varianzen für $ \epsilon=0.001 $ }
	\includegraphics[width=\textwidth]{plots/eps0001.png} 
\end{figure}

\begin{align*}
	\alpha  &=    2.22754   \\
	\beta   &=    6.07184   \\
	\gamma  &=    3   \\
\text{numErr}  &= 0.000118023   \quad \text{(geschätzter numerischer Fehler)}\\
\text{statErr} &= 0.000694324  \quad  \text{(geschätzter statistischer Fehler)}\\
\text{error}   &= 0.000812347  \quad  \text{(geschätzter Gesamtfehler)}\\
\end{align*}

Betrachten wir die MLMC Kosten gegen die Genauigkeit $ \epsilon $ erhalten wir so:
\begin{figure}[H]
	\centering
	\captionabove{Vergleich über $ \epsilon $}
	\includegraphics[width=\textwidth]{plots/mlmctable.png} 
\end{figure}


\subsection{MLMC Lösung}
Zu guter Letzt ist es uns zudem über die Verarbeitung der gespeicherten VTK-Dateien möglich, die berechneten Lösungen, welche uns in Form von Gitterdaten vorliegen, zu einer MLMC-Lösung zu kombinieren. Auf die gleiche Weise lässt sich zudem auch ein Gesamt-Flussvektorfeld berechnen. Dazu addieren wir die Gitterdaten der Samples auf dem jeweiligen Level, subtrahieren überall außer im Basislevel $ 4 $ jeweils die Summe der Coarse-Samples, skalieren mit der Anzahl der betrachteten Samples und kombinieren anschließend die so entstandenen Monte-Carlo Lösungen zu einer Multilevel Monte Carlo Lösung.
Einer der wichtigsten Schritte ist dabei das sogenannten 'Upscaling', welches uns ermöglicht, verschieden feine Gitter miteinander zu verrechnen. In unserem Fall ist dies recht einfach, da wir im Ort reguläre Gitter mit identischen Quadraten und in der Zeit eine äquidistante Zerlegung betrachten. Der zugehörige Code findet sich ebenfalls in \cite{githubvtk} in der Datei $'mlmc\_solution.py'$.
Auch zu den so entstehenden Gitterdaten können wir wieder entsprechende Schaubilder generieren:
\begin{figure}[H]
	\centering
	\captionabove{MLMC-Lösung für den Durchlauf $ \epsilon = 0.001 $}
	\includegraphics[width=\textwidth]{plots/mlmc.png} 
\end{figure}
Wir haben so die Lösung bestimmt, welche ausgewertet im gewählten Zielfunktional gerade den Wert des durch die Multilevel Monte Carlo Methode bestimmten Erwartungswertes
$ \mathbb{E}[Q] = 0.229027 $ ergibt und zudem auf die gleiche Weise aus den Lösungen der partiellen Differentialgleichungen für die zufällig bestimmten Flussvektorfelder $ q(\omega_i) $ hervorgeht wie $ \mathbb{E}[Q] $ aus den Werten $ Q(\omega_i) $.

