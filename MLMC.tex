% !TeX root = bachelorarbeit.tex

Nachdem wir im dritten Abschnitt die Monte Carlo Methode betrachtet haben, wollen wir uns nun einer Weiterentwicklung der Monte Carlo Methode, der sogenannten Multi Level Monte Carlo Methode zuwenden. Grundsätzlich liegt dieselbe Situation vor wie bei der Monte Carlo Methode:
Wir wollen wieder eine Größe bestimmen, welche sich nach geeigneter Modellierung in der Form eines Erwartungswertes $ \mathbb{E}[X] $ einer Zufallsvariablen $ X $ schreiben lässt. Besonders wenn diese Größe mit der Lösung von gewöhnlichen oder partiellen Differentialgleichungen, wie wir sie später betrachten wollen, hat man nun jedoch die Wahl, wie genau die numerische Lösung des zugrunde liegenden Problems, z.B. der Differentialgleichung, erfolgen soll. Beispielsweise können wir im Falle der numerischen Lösung von Differentialgleichung Zeitschrittweiten und/oder Gitterweiten der Ortsdiskretisierung festlegen. Wir werden dann in diesem Zusammenhang auch von verschiedenen (Genauigkeits-)Leveln sprechen. An dieser Stelle tritt stets ein typischer Zwiespalt auf:
\begin{itemize}
	\item Zu Einen wollen wir möglichst genau rechnen. Dies legt die Wahl von besonders kleinen Zeitschrittweiten bzw. feinen Gittern zur Ortsdiskretisierung nahe.
	\item Zum Anderen wollen wir die Anzahl der Rechenschritte bzw. die Rechenzeit möglichst gering halten. Dies spricht hingegen für große Zeitschritte bzw. grobe Gitter.
\end{itemize}
Zusätzlich zu der oft bereits alleine anspruchsvollen Aufgabe solche Probleme numerisch zu lösen, müssen wir also stets einen für unsere Bedürfnisse passenden Kompromiss aus möglichst genauer numerischer Approximation und geringem (oder zumindest machbarem) Rechenaufwand eingehen. Obwohl dies zunächst wie eine zusätzliche Hürde erscheint und Mehraufwand vermuten lässt, stellt sich heraus, dass solche eine Wahl der Genauigkeit im Kontext von Monte Carlo Methode sich durchaus als Nützlich erweisen kann. 
Die Multi Level Monte Carlo Methode, wir werden im folgenden auch oft vom sogenannten Multi Level Monte Carlo Schätzer sprechen, ist der Prototyp einer Familie sogenannter Varianz-reduzierender Methoden, welche das Ziel haben die naive Monte Carlo Methode in Sachen Konvergenzrate und Effizienz zu schlagen. Bevor wir erklären wie genau die Multilevel Monte Carlo Methode im Allgemeinen dabei vorgeht, möchten wir die Funktionsweise wieder anhand eines Beispiels erklären, welches in \cite{heinrich2001multilevel} ausführlich erklärt wird.

\begin{Beispiel}(Wieder ein Integral über $[0,1]^d$)\\
	Wie bereits im letzten Abschnitt setzen wir uns die Aufgabe das Integral einer Funktion $ f $ zunächst über $ [0,1]^d $ zu bestimmen. Damit wir aber überhaupt in oben erklärte Situation kommen und von verschiedenen 'Leveln' sprechen können, sei $ f $ nun zusätzlich abhängig von einem Parameter $ \lambda \in \Lambda \subseteq \R^{d_2}$, also $f : \Lambda \times [0,1]^d \to \R $. Um bei den folgenden Überlegungen die Notation so schlank wie möglich zu halten, betrachten wir an dieser Stelle nur einen konkreten Spezialfall: \\
	Sei $ d = d_2 = 1 $ und $ f \in C([0,1]^2,\R) $, d.h. wir wollen das Integral 
	\[
		I(\lambda) = \int_{0}^{1} f(\lambda,u) \du
	\]
	für alle $ \lambda \in \Lambda = [0,1] $ bestimmen, wir suchen also nach einer Funktion in Abhängigkeit von $ \lambda $.\\
	
	\textbf{Monte Carlo Schätzer für $I(\lambda)$}\\
	Wollen wir an dieser Stelle einen normalen Monte Carlo Schätzer nutzen, stellt sich die Frage, wie wir mit dem zusätzlichen Parameter umsetzen sollen. Die wohl naheliegendste und einfachste Idee ist, zunächst für ein festes $ h \in \N $ ein Gitter $ \{ \lambda_i = \frac{i}{h}, i=0,\dots,h\} $ festzulegen und für jedes $ \lambda_i $ wie im letzten Abschnitt vorzugehen und für ein $ n \in \N $
	\[
		I(\lambda_i) \approx \hat{I}(\lambda_i) \coloneqq \frac{1}{n} \sum_{k=1}^{n} f(\lambda_i,x_k)
	\]
	zu schätzen. Dabei seien wieder $ (x_k)_{k=1,\dots,n} $ Realisierungen von unabhängigen auf $ [0,1] $ gleichverteilten Zufallsvariablen $ (X_k)_{k=1,\dots,n} $.
	Anschließend lässt sich aus den so ermittelten Werten durch Interpolation einen Schätzer für die gesamte Funktion $ I(\lambda) $ bestimmen. Grundsätzlich sind verschiedene Interpolationsansätze möglich. Für dieses grundlegende Beispiel wählen wir stückweise lineare Interpolation. Wir erhalten so für alle $ \lambda \in \Lambda $:
	\[
		I(\lambda) \approx (PI)(\lambda) = \sum_{i=0}^{h} \hat{I}(\lambda_i) \varphi_i(\lambda)
	\]
	mit $ \varphi_i \coloneqq \mathds{1}_{ \{\abs{\lambda - \lambda_i} \leq h \} }(1-h\abs{\lambda-\lambda_i})$. Ein solcher Interpolationsansatz lässt sich insbesondere auf mehrdimensionale Gitter übertragen.
%	Alternativ $ \alpha_i \coloneqq \frac{I(\lambda_{i+1}) - I(\lambda_i)}{\lambda_{i+1}-\lambda_i} $ und $ \varphi_i(\lambda) \coloneqq \mathds{1}_{\lambda \in [\lambda_i,\lambda_{i+1}]} \left(  \alpha_i\lambda + (I(\lambda_i) - \alpha_i \lambda_i) \right)$.
	Somit erhalten wir für $ I(\lambda) $:
	\[
		I(\lambda) \approx \mathcal{I}_{MC}(\lambda) \coloneqq \sum_{i=0}^{h} \left( \frac{1}{n}\sum_{k=1}^{n} f(\lambda_i, x_k)\right) \varphi_i (\lambda) = \frac{1}{n} \sum_{k=1}^{n} (Pf(\cdot,x_k))(\lambda)
	\]
	Als Fehler dieser Methode können wir den sogenannten 'root mean square error' verbunden mit einer beliebigen Norm betrachten, wir wählen hierbei die $ L^2 $-Norm.
	Wir erhalten so 
	\[ 
	\epsilon(\mathcal{I}_{MC})  = \left( \mathbb{E} [\lVert I -  \mathcal{I}_{MC} \rVert_{L^2([0,1])}^2] \right)^{\frac{1}{2}} = \left( \mathbb{E} \left[ \int\limits_{0}^{1} \abs{I(\lambda) - \mathcal{I}_{MC}(\lambda)}^2 \dlam \right] \right)^{\frac{1}{2}}
	\]
	Ist $ f $ zusätzlich stetig differenzierbar im Parameter $ \lambda $, kann gezeigt werden, dass 
	\[
		\epsilon(\mathcal{I}_{MC}) = \mathcal{O}(n^{-\frac{1}{2}}+h^{-1}) \ .
	\].
	Gleichzeitig ist die Anzahl der arithmetischen Operationen, Funktionsaufrufe und generierter Zufallszahlen in $ \mathcal{O}(hn) $.
	Wir sehen also, dass wir an dieser Stelle genau diesen Zwiespalt antreffen, welchen wir zuvor abstrakt beschrieben haben. Aus diesem Grund wollen wir nun einen Multilevel Monte Carlo Schätzer für $ I(\lambda) $ einführen.\\	
	
	\textbf{Multilevel Monte Carlo Schätzer für $ I(\lambda) $}\\
	Wir betrachten nun eine Familie von Gittern $ \{ \lambda_{li} = \frac{i}{h_l} : h_l = 2^l \ , i=0,1,\dots h_l \} $ für $ l = 0,\dots,m $.
	Analog zu oben führen wir zugehörige Interpolationsoperatoren 
	\[
	 (P_l I)(\lambda) = \sum_{i=0}^{h_l} \hat{I}(\lambda_{li}) \varphi_{li} \quad (l = 0,\dots,m)
	 \]
	 ein. Wir können nun also insbesondere $ P \coloneqq P_m $ also Teleskopsumme darstellen. Es gilt nämlich:
	 \[
	 	P = P_m = P_0 + \sum_{l=1}^{m} (P_l-P_{l-1}) \ .
	 \]
	 Der Monte Carlo Schätzer von oben lässt sich (mit $ P_{-1} \coloneqq 0 $)dann durch 
	 \[	
	 \mathcal{I}_{MC} = \sum\limits_{l=0}^{m} \frac{1}{n} \sum\limits_{k=1}^{n} (P_l-P_{l-1})f(\cdot,x_k)	
	 \]
	  umschreiben. Um nun tatsächlich einen Nutzen aus der Aufteilung in verschiedene Level zu ziehen und einen guten Kompromiss zwischen Kosten und Fehler herzustellen erlauben wir nun zusätzlich die Anzahl der Zufallsauswertungen $ n $ von Level zu Level zu variieren. 
	  Wir wählen also $ (n_l)_{l=0,\dots,m} \in \N^{m+1}  $.  Außerdem seien $ \{ X_{lj} , l=0,\dots,m \ , j= 0,\dots,n_l\} $ unabhängige auf $ [0,1] $ gleichverteilte Zufallsvariablen und $ (x_{lj})_{l=0,\dots,m \ ,j=0,\dots,n_l} $ zugehörige Realisierungen.
	  Dann erhalten wir den Multilevel Monte Carlo Schätzer 
	  \[
	   I(\lambda) \approx \mathcal{I}_{MLMC}(\lambda) = \sum_{l=0}^{m} \frac{1}{n_l} \sum_{k=1}^{n_l} ((P_l - P_{l-1}) f(\cdot,x_{lj}))(\lambda) \ .
	  \]
	  Der bedeutendste Schritt ist an dieser Stelle eine passende Wahl der $ n_l $. Bei diesem Beispiel wollen wir uns darauf beschränken eine passende Wahl anzugeben und den Nutzen hervorzuheben, welchen wir durch diese Wahl erlangen. So zeigt sich, dass eine passende Wahl beispielsweise durch $ n_l = \Theta(2^{-\frac{3l}{2}n})$ für ein $ n \in \N $ groß genug gegeben ist. 
	  Dann kann für den analog wie für den MC-Schätzer definierten (RMSE-)Fehler gezeigt werden, dass 
	  \[
	  	\epsilon(\mathcal{I}_{MLMC}) = \mathcal{O}(n^{-\frac{1}{2}} + n^{-\frac{1}{2}}) = \mathcal{O}(n^{-\frac{1}{2}})
	  \].
	  Zugleich ist die Anzahl der benötigten Rechenoperationen inklusive Funktions- und Zufallszahlauswertungen diesmal in $ \mathcal{O}(n) $.
	  Verglichen mit der Standard (Ein-Level) Monte Carlo Methode können wir nun also eine Approximation für die gesamte Familie von Integralen $ I(\lambda) $ mit einem Fehler von $ \mathcal{O}(n^{-\frac{1}{2}}) $, aber den Kosten von $ \mathcal{O}(n) $  berechnen. Das ist durchaus erstaunlich, denn bereits die Kosten der Auswertung eines einzigen Integrals $ I(\lambda) $ für ein festes $ \lambda \in \Lambda $ liegen in $ \mathcal{O}(n) $. 
\end{Beispiel}

Wir sehen also, dass die Multilevel Monte Carlo Methode in Situationen, in denen wir bei der Wahl von Zeitschrittweiten und/oder feinen Gittern zur Ortsdiskretisierung zwischen Anzahl an Rechenoperationen und Genauigkeit einen Kompromiss finden müssen, einen Ein-Level Ansatz, wie die Standard Monte Carlo Methode, durchaus übertreffen kann.
Der Kern dieser Methode bildet dabei eine geschickte Wahl der Anzahl $ n_l $ der Zufallssamples, welche wir auf je einem Level auswerten. Wie wir in unserem Fall diese Wahl durchführen soll an anderer Stelle in Abschnitt \ref{MLMCTP} ausführlich erläutert werden, in welchem wir die bisher zunächst beispielhaft anhand der Integration eingeführte Multilevel Monte Carlo Methode auf das probabilistische Transportproblem, welches wir in Abschnitt \ref{TP} bereits näher beleuchtet haben, übertragen werden.
Mehr zu Monte Carlo und Multilevel Monte Carlo Methoden für Parameterintegrale findet sich neben \cite{heinrich2001multilevel} auch in \cite{heinrich1992random}.

\subsection{Konvergenz und Genauigkeit}
Da wir in Abschnitt \ref{MLMCTP} noch einmal ausführlich auf die Eigenschaften des Verfahrens für unsere konkrete Anwendung eingehen werden, soll dieser Unterabschnitt eher noch einmal etwas allgemeiner auf die stochastischen Hintergründe eingehen. Als Referenz ist hierbei das Kapitel 9.5 über Monte-Carlo Funktionen in \cite{sullivan2015introduction} zu nennen. 
Betrachten wir also wieder etwas allgemeiner eine Folge unabhängig Zufallsvariablen $ Y_{1},Y_{2}\dots$ mit zugehörigen Realisierungen $ y_{1}, y_{2},\dots $. Diese sollen dabei alle die identische Verteilung wie eine weitere Zufallsvariable $ Y $ mit zugehöriger Dichte $ g_Y $ besitzen.
Wir wollen diesmal den Erwartungswert einer Zufallsvariablen $ X $ berechnen, wobei wir $ X $ mithilfe einer messbaren Funktion $ f $, die alle (unten aufgeführten) Voraussetzungen des Transformationssatzes erfülle, folgendermaßen ausgedrückt werden kann:
\[
	X = f(Y)
\]
Wir fordern nun wieder, dass der Erwartungswert $ \mathbb{E}[|X|] < \infty $ existiert, und diese Forderung ist für die Konvergenz der Methode ebenso wichtig wie scharf. Wollen wir uns überlegen, was das maßtheoretisch bedeutet, erhalten wir:
Ist für  $  \{ g_Y > 0 \} \subseteq O $ die Menge $ O $ offen und $ f:\R \to \R $ eine Borel-messbare Abbildung, deren Restriktion auf $ O $ stetig differenzierbar ist, eine nirgends verschwindende Funktionaldeterminante besitze und $ O $ bijektiv auf eine Menge $ V \subset \R $ abbilde.
Dann muss die Dichte $ g_X $ der Zufallsvariable $ X $ auf $ V $ integrierbar sein. Dabei gilt für die Dichte von $ X $ nach dem Transformationssatz:
\[
 	g_X(t) \coloneqq 
 	\begin{cases}
 	\frac{g_y(f^-1(t))}{\abs{\det f'(f^-1(t))}} \ \quad ,\text{falls }t\in V\\
 	0 \qquad \qquad \qquad, \text{sonst} 	
 	\end{cases}
\]
Wir nehmen nun außerdem an, dass wir über eine Hierarchie 
$ (f_l)_{l \in \{ 0,\dots,L \} } $ verfügen. Dabei sei $ f = f_L $ und wir bezeichnen $ l $ als Level-Parameter.
Aufgrund der Linearität des Erwartungswertes kann der Erwartungswert von $ X $ dann folgendermaßen ausgedrückt werden:
\[
	\mathbb{E}[X] = \mathbb{E}[f(Y)] = \mathbb{E}[f_0[Y]] + \sum_{l=1}^{L} \mathbb{E}[f_l(Y) - f_{l-1}(Y)]
\]
Wir können nun jeden Summanden einzeln durch einen Monte Carlo Ansatz schätzen. Dazu seien $ (Y_{l,i})_{l\in\{0,\dots,L\},i \in \{1,\dots,n_l \} }  $ unabhängige Zufallsvariablen aus der Folge $ (Y_i)_{i \in \N} $. Dann gilt:
\[
 \mathbb{E}[X] \approx \frac{1}{n_0} \sum_{i=1}^{n_0}f_0(Y_{0,i}) + \sum_{l=1}^{L} \frac{1}{n_l}\sum_{i=1}^{n_l} \left( f_l(Y_{l,i}) - f_{l-1}(Y_{l,i})\right)
\]
An dieser Stelle scheint obige Darstellung keinen wirklichen Vorteil gegenüber dem Standard Monte Carlo Schätzer zu besitzen, wir müssen aber nun beachten, dass zum Einen die Anzahl der benötigten Rechenoperation zur Berechnung von $ f_l(Y_{l,i}) $ unter Umständen für niedrige Werte $ l $ deutlich geringer ausfällt, als dies für größere $ l $ der Fall ist.
Zum Anderen gilt für den Fehler der Monte Carlo Schätzung (vgl. Abschnitt \ref{MC}), dass der Fehler des $l$-ten Summanden wie $ \sqrt{\frac{\mathbb{V}[f_l(Y) - f_{l-1}(Y)]}{n_l}} $ konvergiert. Das heißt insbesondere, dass falls $ \mathbb{V}[f_l(Y)-f_{l-1}(Y)] $ klein ausfällt, auch kleinere $ n_l $ gewählt werden können, als bei der Standard Monte Carlo Methode, für welche bei einer großen Varianz $ \mathbb{V}[f(Y)] = \mathbb{V}[f_L(Y)] $ ein sehr großes $ n=n_L $ für eine gute Approximation benötigt werden. Andererseits müssen wir aber auch beachten, dass wir uns damit zusätzlich zum Schätzfehler, durch die Approximation von $ f $, auch einen Approximationsfehler einhandeln. In der Praxis, wie z.B. beim partiellen Differentialgleichungen, verfügen wir aber auch oft nicht über $ f $ selbst, sondern nur verschieden gute Approximationen. Wir müssen also in der späteren Anwendung ganz genau prüfen, wie und ob wir aus der Multilevel Monte Carlo Methode tatsächlich einen Nutzen ziehen können. Diese Grundidee, die Varianz klein zu halten, damit die benötigte Anzahl der auszuwertenden Zufallssamples gering gehalten werden kann, ist namensgebend für die sogenannten 'Varianz reduzierenden Methoden' zur Verbesserung der Monte Carlo Methode. Weitere Details der Konvergenzanalyse finden sich in für unser Problem angepasster Form in Abschnitt \ref{MLMCTP}.
Bevor wir dazu kommen können, müssen wir aber im Folgenden Abschnitt zunächst das zu betrachtende Problem sowie zugehörige Löser einführen, welche später die Rolle der Approximationen $ f_l $ übernehmen werden.